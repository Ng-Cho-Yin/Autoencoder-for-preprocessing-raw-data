{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Tensorflow / Keras\nfrom tensorflow import keras # for building Neural Networks\nprint('Tensorflow/Keras: %s' % keras.__version__) # print version\nfrom keras.models import Model, load_model # for creating a Neural Network Autoencoder model\nfrom keras import Input # for instantiating a keras tensor\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization # for adding layers to AE model\nfrom tensorflow.keras.utils import plot_model # for plotting model diagram\n\n# Data manipulation\nimport pandas as pd # for data manipulation\nprint('pandas: %s' % pd.__version__) # print version\n\n# Sklearn\nimport sklearn # for model evaluation\nprint('sklearn: %s' % sklearn.__version__) # print version\nfrom sklearn.preprocessing import MinMaxScaler # For rescaling metrics to fit into 0 to 1 range\nfrom sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n\n# Visualization\nimport matplotlib \nimport matplotlib.pyplot as plt # for plotting model loss\nprint('matplotlib: %s' % matplotlib.__version__) # print version\nimport graphviz # for showing model diagram\nprint('graphviz: %s' % graphviz.__version__) # print version\n\n# Other utilities\nimport sys\nimport os\n\n# Assign main directory to a variable\nmain_dir=os.path.dirname(sys.path[0])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-12T08:47:03.368975Z","iopub.execute_input":"2022-07-12T08:47:03.370208Z","iopub.status.idle":"2022-07-12T08:47:14.136543Z","shell.execute_reply.started":"2022-07-12T08:47:03.370098Z","shell.execute_reply":"2022-07-12T08:47:14.135623Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n# Set Pandas options to display more columns\npd.options.display.max_columns=50\n\n# Read in the weather data csv\ndf=pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv', encoding='utf-8')\n\n# Drop rows where any of the values are missing. \n# Note, in this case it drops ~60% of the rows. Since we are using this data just as an example, it's ok.\n# However, when you work with your own data, you may want to explore other options to fill in NA's with, say, mean values\ndf=df.dropna(axis=0)\n\n# Create a flag for RainToday\ndf['RainTodayFlag']=df['RainToday'].apply(lambda x: 1 if x=='Yes' else 0)\n\n# Show a snaphsot of data\ndf\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T08:47:52.769038Z","iopub.execute_input":"2022-07-12T08:47:52.769412Z","iopub.status.idle":"2022-07-12T08:47:53.500754Z","shell.execute_reply.started":"2022-07-12T08:47:52.769384Z","shell.execute_reply":"2022-07-12T08:47:53.499535Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Select data for modeling\nX=df[['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', \n      'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',  \n      'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'RainTodayFlag']]\n\n# Scale training data so it is between 0 and 1\nscaler = MinMaxScaler()\nX_scaled=scaler.fit_transform(X)\n\n# Create training and testing samples\nX_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T08:49:20.132126Z","iopub.execute_input":"2022-07-12T08:49:20.132527Z","iopub.status.idle":"2022-07-12T08:49:20.172324Z","shell.execute_reply.started":"2022-07-12T08:49:20.132496Z","shell.execute_reply":"2022-07-12T08:49:20.170913Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"(round(float(X_train.shape[1]) / 2.0))","metadata":{"execution":{"iopub.status.busy":"2022-07-12T08:55:35.663931Z","iopub.execute_input":"2022-07-12T08:55:35.664776Z","iopub.status.idle":"2022-07-12T08:55:35.672083Z","shell.execute_reply.started":"2022-07-12T08:55:35.664733Z","shell.execute_reply":"2022-07-12T08:55:35.670989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Building and training an Autoencoder model","metadata":{}},{"cell_type":"code","source":"#--- Define Shapes\nn_inputs=X_train.shape[1] # number of input neurons = the number of features in X_train\nn_bottleneck=(round(float(n_inputs) / 2.0)) # bottleneck to have half the number of neurons \n\n#--- Input Layer \nvisible = Input(shape=(n_inputs,), name='Input-Layer') # Specify input shape\n\n#--- Encoder Layer\ne = Dense(units=n_inputs, name='Encoder-Layer')(visible)\ne = BatchNormalization(name='Encoder-Layer-Normalization')(e)\ne = LeakyReLU(name='Encoder-Layer-Activation')(e)\n\n#--- Bottleneck\nbottleneck = Dense(units=n_bottleneck, name='Bottleneck-Layer')(e)\n\n#--- Decoder Layer\nd = Dense(units=n_inputs, name='Decoder-Layer')(bottleneck)\nd = BatchNormalization(name='Decoder-Layer-Normalization')(d)\nd = LeakyReLU(name='Decoder-Layer-Activation')(d)\n\n#--- Output layer\noutput = Dense(units=n_inputs, activation='linear', name='Output-Layer')(d)\n\n# Define autoencoder model\nmodel = Model(inputs=visible, outputs=output, name='Autoencoder-Model')\n\n# Compile autoencoder model\nmodel.compile(optimizer='adam', loss='mse')\n\n# Print model summary\nprint(model.summary())\n\n# Plot the autoencoder model diagram\nplot_model(model, to_file='./Autoencoder.png', show_shapes=True, dpi=300)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-12T08:58:19.490544Z","iopub.execute_input":"2022-07-12T08:58:19.490978Z","iopub.status.idle":"2022-07-12T08:58:20.182155Z","shell.execute_reply.started":"2022-07-12T08:58:19.490927Z","shell.execute_reply":"2022-07-12T08:58:20.181033Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n# Fit the autoencoder model to reconstruct input\nhistory = model.fit(X_train, X_train, epochs=10, batch_size=16, verbose=1, validation_data=(X_test, X_test))\n\n# Plot a loss chart\nfig, ax = plt.subplots(figsize=(16,9), dpi=300)\nplt.title(label='Model Loss by Epoch', loc='center')\n\nax.plot(history.history['loss'], label='Training Data', color='black')\nax.plot(history.history['val_loss'], label='Test Data', color='red')\nax.set(xlabel='Epoch', ylabel='Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-12T08:59:16.746024Z","iopub.execute_input":"2022-07-12T08:59:16.746409Z","iopub.status.idle":"2022-07-12T09:00:21.884166Z","shell.execute_reply.started":"2022-07-12T08:59:16.746375Z","shell.execute_reply":"2022-07-12T09:00:21.883344Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n# Define an encoder model without the decoder\nencoder = Model(inputs=visible, outputs=bottleneck)\n\n# Compile encoder model\nencoder.compile(optimizer='adam', loss='mse')\n\n# Save the encoder model to file\nencoder.save('./encoder.h5')\n\n# Plot the autoencoder model diagram\nplot_model(encoder, to_file='./Encoder_only.png', show_shapes=True, dpi=300)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:01:48.302246Z","iopub.execute_input":"2022-07-12T09:01:48.302635Z","iopub.status.idle":"2022-07-12T09:01:48.607819Z","shell.execute_reply.started":"2022-07-12T09:01:48.302598Z","shell.execute_reply":"2022-07-12T09:01:48.606336Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Load the model from file\nencoder = load_model('../input/autoencoder-ausweather/encoder.h5')\n\n# Encode train and test data\nX_train_encoded = encoder.predict(X_train)\nX_test_encoded = encoder.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:06:23.233409Z","iopub.execute_input":"2022-07-12T09:06:23.233822Z","iopub.status.idle":"2022-07-12T09:06:24.957237Z","shell.execute_reply.started":"2022-07-12T09:06:23.233783Z","shell.execute_reply":"2022-07-12T09:06:24.956070Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:06:53.914786Z","iopub.execute_input":"2022-07-12T09:06:53.915338Z","iopub.status.idle":"2022-07-12T09:06:53.924419Z","shell.execute_reply.started":"2022-07-12T09:06:53.915281Z","shell.execute_reply":"2022-07-12T09:06:53.923229Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_test_encoded.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-12T09:07:04.820023Z","iopub.execute_input":"2022-07-12T09:07:04.820438Z","iopub.status.idle":"2022-07-12T09:07:04.827037Z","shell.execute_reply.started":"2022-07-12T09:07:04.820405Z","shell.execute_reply":"2022-07-12T09:07:04.826156Z"},"trusted":true},"execution_count":21,"outputs":[]}]}